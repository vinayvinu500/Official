{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe above technique is also called as retrieval augmentation generation because we retrieve relevant information from an external knowledge base and give that information to our LLM. \\nthe external knowledge base is our window into the world beyond the training data. Because practice is more valuable than 1000 words\\n\\nthe general paradigm that we are using is ReAct that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making tasks\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project \n",
    "\"\"\"\n",
    "***Stack***: OPL (OpenAI, Pinecone, Langchain) / OCL (OpenAI, Chromdb, Langchain)\n",
    "\n",
    "***Goal***\n",
    "- Why shouldn't be using ChatGPT instead rather than creating on our own?\n",
    "    - we should be taking care of data privacy policies and should not be feeding our own private documents\n",
    "    - with ChatGPT knowledge is limited to September 2021\n",
    "\n",
    "***Learning***\n",
    "- How can LLMs learn new knowledge?\n",
    "    - Fine-tuning on a training set: is most natural way to teach the model knowledge, but it can be time consuming and expensive | its also builts long term memory, which is not always necessary\n",
    "    - Model inputs: means inserting the knowledge into an input message. for example, we can send an entire book or PDF document to the model as an input message and then we can start questions on topics found in the input message. This is good way to build short term memory for the model\n",
    "    When we have a large corpus of text, it can be difficult to use model inputs because each model is limited to maximum of tokens, which is most cases is around 4000. for example, we cannot simply send the text from a 500 page document to the model because this will exceed the maximum number of tokens that the model supports\n",
    "    Note: the recommended approach is to use model inputs with embedded based search | embeddings are simple to implement and work especially well with questions\n",
    "\n",
    "***pipeline***\n",
    "- 1. Prepare the document (once per document): firstly, we prepare the search data and we'll do that once per document\n",
    "a) Load the data into Langchain Documents: load the data into launching documents\n",
    "b) Split the documents into chunks: split the documents into short and mostly self-contained sections called chunks\n",
    "c) Embed the chunks into numeric vectors: embedd the chunks into numeric vectors using an embedding model such as OpenAI's text embedding ADA 002\n",
    "d) Save the chunks and the embeddings to a vector database: saving the chunks and embeddings to a vector database such as Pinecone, Chroma, Milvus or Quadrant\n",
    "\n",
    "- 2. Search (once per query)\n",
    "a) Embedd the user's question.\n",
    "b) using the question's embedding and the chunk embeddings, rank the vectors by similarity(Cosine or Euclidean distance) to the question's embedding. The nearest vectors represent chunks similar to the question\n",
    "\n",
    "- 3. Ask (once per query)\n",
    "a) Insert the question and the most relevant chunks into a message(2(b)) to a GPT model.\n",
    "b) Return GPT's answer.\n",
    "\"\"\"\n",
    "\n",
    "# Note\n",
    "\"\"\"\n",
    "the above technique is also called as retrieval augmentation generation because we retrieve relevant information from an external knowledge base and give that information to our LLM. \n",
    "the external knowledge base is our window into the world beyond the training data. Because practice is more valuable than 1000 words\n",
    "\n",
    "the general paradigm that we are using is ReAct that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making tasks\n",
    "\n",
    "# What is RAG\n",
    "- RAG stands for Retrieval Augmented Generation and its a technique that combines an LLM way to search for information\n",
    "- this lets the model look at stuff like private documents or database while its generating text\n",
    "- RAG helps overcome knowledge limits, makes answers more factual, and ensure the model handle complex questions\n",
    "- In RAG system, external data is retrieved and then passed it to llm when during the generation step \n",
    "\n",
    "# What is Chroma db\n",
    "- Chroma is an opensource in-memory vector store, making it a better fit for small to medium size projects \n",
    "- we don't need a seperate server or hosting for it\n",
    "- where we don't need to mess around with indexes and namespaces, which saves time and effort\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technologies\n",
    "# Document Loaders: Transform loaders | public | proprietary dataset or service loaders\n",
    "# link: https://python.langchain.com/docs/modules/data_connection/document_loaders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Sucessfull!\n"
     ]
    }
   ],
   "source": [
    "# Environmental variables\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "try: \n",
    "    file = '../LLM/.env'\n",
    "    keys = find_dotenv(file,raise_error_if_not_found=True)\n",
    "    load_dotenv(keys, override=True)\n",
    "    # print(os.environ.get('OPENAI_API_KEY'))\n",
    "    print(\"Initialize Sucessfull!\")\n",
    "except:\n",
    "    print(\"Not Initialized!!!\")\n",
    "    raise Exception(\"Need to Initialize Again...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npypdf\\ndocx2txt\\ntqdm\\nwikipedia\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requirements.txt # need to restart the kernel\n",
    "\"\"\"\n",
    "pypdf\n",
    "docx2txt\n",
    "tqdm\n",
    "wikipedia\n",
    "pinecone-client\n",
    "chromadb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# document loaders\n",
    "from langchain_community import document_loaders\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # By default, the characters it tries to split on are double backslash N and whitespace\n",
    "import tiktoken\n",
    "\n",
    "# vector database\n",
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import PodSpec\n",
    "\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Langchain Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the '../files/MySQL/C3-WK01-DY02-PracticeExercise.pdf'\n",
      "Total '4' Pages in the 'C3-WK01-DY02-PracticeExercise.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Load the document\n",
    "def load_document(file):\n",
    "    \"\"\"Functions links the PDFs using library called PyPDF into an array of documents where each document contains the page, content and metadata with a page number.\"\"\"\n",
    "    # prevent from circular dependencies and benefit from a more reliable refactoring of our code. | if we utilize the function and it will work because it contains everthing it int\n",
    "    # from langchain.document_loaders import PyPDFLoader \n",
    "    \n",
    "    # import json\n",
    "    # from pathlib import Path\n",
    "    name, ext = os.path.splitext(file) # file.split('/')[-2], file.split('/')[-1]\n",
    "\n",
    "    loader = {\n",
    "        '.pdf': document_loaders.PyPDFLoader(file),\n",
    "        '.docx': document_loaders.Docx2txtLoader(file),\n",
    "        '.txt': document_loaders.TextLoader(file),\n",
    "        '.csv': document_loaders.CSVLoader(file),\n",
    "        '.py': document_loaders.PythonLoader(file),\n",
    "        '.html': document_loaders.BSHTMLLoader(file), # UnstructuredHTMLLoader(file)\n",
    "        # '.json': json.loads(Path(file).read_text())\n",
    "    } # url of the file or file path in a file system\n",
    "\n",
    "    if ext not in loader.keys():\n",
    "        print(\"Extension Doesn't Exists!\")\n",
    "        return None\n",
    "    \n",
    "    if ext == '.json':\n",
    "        return loader[ext]\n",
    "    \n",
    "    print(f\"Loading the '{file}'\")\n",
    "    data = loader[ext].load_and_split() if ext == '.pdf' else loader[ext].load() # this will return a list of langchain documents, one document for each page\n",
    "    return data # data is splitted by pages and we can use indexes to display a specific page\n",
    "\n",
    "# Load all the documents : https://python.langchain.com/docs/modules/data_connection/document_loaders/file_directory\n",
    "def load_all_documents(dirpath):\n",
    "    \"\"\"Function accepts the directory path as an argument and return the list of documents(page_content, meta_data)\"\"\"\n",
    "    name, ext = os.path.splitext(file) # file.split('/')[-2], file.split('/')[-1]\n",
    "\n",
    "    loader = {\n",
    "        '.pdf': document_loaders.DirectoryLoader(dirpath, show_progress=True, use_multithreading=True, loader_cls=document_loaders.PyPDFLoader),\n",
    "        '.docx': document_loaders.DirectoryLoader(dirpath, show_progress=True, use_multithreading=True, loader_cls=document_loaders.Docx2txtLoader),\n",
    "        '.txt': document_loaders.DirectoryLoader(dirpath, show_progress=True, use_multithreading=True, loader_cls=document_loaders.TextLoader, loader_kwargs={'autodetect_encoding':True}),\n",
    "        '.csv': document_loaders.DirectoryLoader(dirpath, show_progress=True, use_multithreading=True, loader_cls=document_loaders.CSVLoader),\n",
    "        '.py': document_loaders.DirectoryLoader(dirpath, show_progress=True, use_multithreading=True, loader_cls=document_loaders.PythonLoader)\n",
    "    } # silent_errors=True which can silenced which could not be loaded\n",
    "\n",
    "    if ext not in loader.keys():\n",
    "        print(\"Extension Doesn't Exists!\")\n",
    "        return None\n",
    "\n",
    "    data = loader[ext].load_and_split() if ext == '.pdf' else loader[ext].load()\n",
    "    print(f\"Documents: {len(data)}\")\n",
    "    return sorted(data, key=lambda x: x.page_content.split('\\n')[0]) # sorted through title of the documents\n",
    "\n",
    "# load from wikipedia\n",
    "def load_wikipedia_documents(query, lang='en', load_max_docs=2):\n",
    "    \"\"\"Functions accepts three arguments <(query, lang, load_max_docs)> whereas query: question | lang: language of text | load_max_docs: maximum documents to return\"\"\"\n",
    "    print(\"Function has been invoked and will take enough time to process based on the maximum document size %s...\" %load_max_docs)\n",
    "    loader = document_loaders.WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "\n",
    "# driver code: files\n",
    "dirpath = \"../files/MySQL\"\n",
    "file = \"../files/MySQL/C3-WK01-DY02-PracticeExercise.pdf\"\n",
    "page = 2\n",
    "\n",
    "# one document at a time\n",
    "data = load_document(file)\n",
    "print(f\"Total '{len(data)}' Pages in the '{file.split('/')[-1]}'\")\n",
    "# print(f'There are \"{len(data[page].page_content)}\" characters at the {page} page.')\n",
    "# print(\"Metadata:\", data[page].metadata)\n",
    "# print(f\"Page {page}: {data[page].page_content}\")\n",
    "\n",
    "# list of documents\n",
    "# data = load_all_documents(dirpath)\n",
    "# data\n",
    "\n",
    "# driver code: wikipedia\n",
    "# data = load_wikipedia_documents('LLM(Large Language Models)')\n",
    "# print(data[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document chunking\n",
    "def data_chunks(data, chunk_size=256, chunk_overlap=0):\n",
    "    \"\"\"Function accepts the document_loader object and returns the chunks and takes two additional arguments as chunk_size & chunk_overlap\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    # print(f\"Chunk Size: {chunk_size}\")\n",
    "    # print(f\"Chunk Overlap: {chunk_overlap}\")\n",
    "    # print(f\"Total Chunks: {len(chunks)}\")\n",
    "    return chunks\n",
    "\n",
    "# embedding costs: tokens \n",
    "def embedding_costs(chunks, model='text-embedding-3-small', price=0.02):\n",
    "    \"\"\"Function accepts text or document as chunks then calculates the embedding costs. By default it will embedd using model='text-embedding-3-small' with price=0.02 \"\"\"\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in chunks])\n",
    "    embed_cost = total_tokens / 1000 * price\n",
    "    # print(f\"Total Tokens: {total_tokens}\")\n",
    "    # print(f\"Embedding Cost in USD: {embed_cost:.6f}\")\n",
    "    return total_tokens, round(embed_cost, 6)\n",
    "\n",
    "# document-chunks-tokens-embeddings calculator\n",
    "def document_chunks_tokens_embeds_calculator(data, chunk_size=256, chunk_overlap=0, model='text-embedding-3-small', price=0.02):\n",
    "    \"\"\"Function accepts three arguments\n",
    "    data: document_loaders object\n",
    "    chunk_size & chunk_overlap\n",
    "    model: describes embedding model\n",
    "    and prints chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs\n",
    "    # and returns chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs\n",
    "    \"\"\"\n",
    "    if chunk_overlap is None:\n",
    "        chunk_overlap = chunk_size // 2 + 1\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size, # should be higher and need to be experiemented\n",
    "        chunk_overlap= chunk_overlap, # overlap between chunks needed to maintain some continuity between them\n",
    "        length_function=len # indicates how the length of chunks is calculated\n",
    "        # The default is to just count the number of characters, but because we work with LLMs and LLMs use tokens \n",
    "        # Instead it should be token counter \n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    tokens = [enc.encode(page.page_content) for page in chunks]\n",
    "    total_tokens = sum(map(len, tokens))\n",
    "    embed_cost = total_tokens / 1000 * price\n",
    "\n",
    "    print(f\"Chunk Size: {chunk_size}\")\n",
    "    print(f\"Chunk Overlap: {chunk_overlap}\")\n",
    "    print(f\"Chunks: {chunks[:5]}\")\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    print(f\"Tokens: {tokens[:5]}\")\n",
    "    print(f\"Total Tokens: {total_tokens}\")\n",
    "    print(f\"Embedding Cost in USD: {embed_cost:.6f}\")\n",
    "\n",
    "    user = input(\"Are you want to continue...[Y/N | y/n]: \")\n",
    "    if user in ('y', 'Y'):\n",
    "        return chunk_size, chunk_overlap, chunks, len(chunks), total_tokens, round(embed_cost, 6)\n",
    "    else:\n",
    "        raise Exception(\"User has raised the error to prevent the process of embedding...\")\n",
    "\n",
    "\n",
    "# driver code: chunks\n",
    "# one document at a time\n",
    "# data = load_document(file)\n",
    "# print(f\"Total '{len(data)}' Pages in the '{file.split('/')[-1]}'\")\n",
    "\n",
    "# chunks = data_chunks(data)\n",
    "# print(f\"There are {len(chunks)} chunks.\")\n",
    "# print(chunks[2].page_content)\n",
    "\n",
    "# total_tokens, embed_costs = embedding_costs(chunks)\n",
    "# print(f\"Total Tokens: {total_tokens}\")\n",
    "# print(f\"Embedding Cost in USD: {embed_costs:.6f}\")\n",
    "\n",
    "# chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs = document_chunks_tokens_embeds_calc(data)\n",
    "    \n",
    "# Use-Case: Customize \n",
    "# data = load_document(file)\n",
    "# print(f\"Total '{len(data)}' Pages in the '{file.split('/')[-1]}'\")\n",
    "# document_chunks_tokens_embeds_calculator(data) # chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs\n",
    "# document_chunks_tokens_embeds_calculator(data, chunk_size=10, chunk_overlap=5) # chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs\n",
    "# document_chunks_tokens_embeds_calculator(data, chunk_size=256, chunk_overlap=None) # chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs\n",
    "# document_chunks_tokens_embeds_calculator(data, chunk_size=1) # chunk_size, chunk_overlap, chunks, total_chunks, total_tokens, embed_costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database: Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The document provides information about SQL transactions, including the structure of a transaction (BEGIN TRANSACTION, SQL STATEMENTS, SAVEPOINT, COMMIT or ROLLBACK), and it also covers the purpose of using the * symbol in a SELECT command in SQL. Additionally, it seems to include a practice exercise related to SQL.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to vector database like Pinecone for fast retrieval through similarity score\n",
    "def insert_or_fetch_pinecone_embeddings(index_name, chunks):\n",
    "    \"\"\"\n",
    "    Function will create index and if the index doesn't exists, embed the chunks and add both the chunks and embeddings into the pinecone index | if the index already exists, the function will just load the embeddings from the index\n",
    "    \n",
    "    function takes two arguments: \n",
    "    index_name: vector database index name\n",
    "    chunks: document_loaders object\n",
    "    \"\"\"\n",
    "    pc = pinecone.Pinecone()\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
    "\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(\"Index exists! Fetching...\", end=' ')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print(\"Completed...\")\n",
    "    else:\n",
    "        print(\"Creating Index %s and embeddings...\" %index_name, end=' ')\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=PodSpec(\n",
    "                environment='gcp-starter'\n",
    "            )\n",
    "        )\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print(\"Sucessfully Upserted the Chunks...\")\n",
    "    return vector_store\n",
    "\n",
    "# Delete the existing index or all the indexes\n",
    "def delete_pinecone_index(index_name=None):\n",
    "    pc = pinecone.Pinecone()\n",
    "    indexes = pc.list_indexes().names()\n",
    "\n",
    "    if pc.list_indexes().names() == []:\n",
    "        print(\"There is no indexes available to delete...\")\n",
    "    elif index_name is None:\n",
    "        print(\"Deleting all the indexes consists of %s\" %indexes, end=' ')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print(\"Done...\")\n",
    "    elif index_name not in indexes:\n",
    "        print(\"Index Doesn't Exists!\")\n",
    "    else:\n",
    "        print(f\"Deleting the index: {index_name}\", end=' ')\n",
    "        pc.delete_index(index_name)\n",
    "        print(\"Done...\")\n",
    "\n",
    "# Asking Questions & Getting the Answers using similarity search \n",
    "def question_answer_bot(vector_store, question, model='gpt-3.5-turbo', temperature=1, search_type='similarity', k=3):\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':k})\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever) # chain_type='stuff' will use all of the text from the documents in the prompt which we got as a result\n",
    "    answer = chain.invoke(question)\n",
    "    return answer\n",
    "\n",
    "# Driver code\n",
    "# data = load_all_documents(dirpath)\n",
    "# chunks = data_chunks(data)\n",
    "# # document_chunks_tokens_embeds_calculator(chunks) # Calculate the Embedding costs\n",
    "\n",
    "# # Ensuring there is no index already created since we are on free-tier plan\n",
    "# delete_pinecone_index()\n",
    "\n",
    "# # Creating the index or returning the existing vector store\n",
    "# index_name = 'glca-da-mysql-practice-exercises'\n",
    "# vector_store = insert_or_fetch_pinecone_embeddings(index_name, chunks) # will return existing vector_store if index already exists or will create new index + upsert embeddings \n",
    "\n",
    "# # Asking Questions & Getting the Answers using similarity search \n",
    "# question = \"\"\"What is the whole document about?\"\"\"\n",
    "# answer = question_answer_bot(vector_store, question)\n",
    "# print(answer)\n",
    "# print(answer['query'])\n",
    "# print(answer['result'])\n",
    "\"\"\"The document provides information about SQL transactions, including the structure of a transaction (BEGIN TRANSACTION, SQL STATEMENTS, SAVEPOINT, COMMIT or ROLLBACK), and it also covers the purpose of using the * symbol in a SELECT command in SQL. Additionally, it seems to include a practice exercise related to SQL.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 49\n",
      "Index exists! Fetching... Completed...\n"
     ]
    }
   ],
   "source": [
    "data = load_all_documents(dirpath)\n",
    "chunks = data_chunks(data)\n",
    "# document_chunks_tokens_embeds_calculator(chunks) # Calculate the Embedding costs\n",
    "\n",
    "# Ensuring there is no index already created since we are on free-tier plan\n",
    "# delete_pinecone_index()\n",
    "\n",
    "# Creating the index or returning the existing vector store\n",
    "index_name = 'glca-da-mysql-practice-exercises'\n",
    "vector_store = insert_or_fetch_pinecone_embeddings(index_name, chunks) # will return existing vector_store if index already exists or will create new index + upsert embeddings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The document provides information about SQL transactions, including the structure of a transaction (BEGIN TRANSACTION, SQL STATEMENTS, SAVEPOINT, COMMIT or ROLLBACK), and it also covers the purpose of using the * symbol in a SELECT command in SQL. Additionally, it seems to include a practice exercise related to SQL.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to train more on the specific document through wikipedia\n",
    "# data = load_wikipedia_documents(\"MySQL\", load_max_docs=50) # https://en.wikipedia.org/wiki/MySQL\n",
    "# chunks = data_chunks(data)\n",
    "# document_chunks_tokens_embeds_calculator(chunks)\n",
    "# index_name='glca-da-mysql-practice-exercises'\n",
    "# vector_store = insert_or_fetch_pinecone_embeddings(index_name, chunks)\n",
    "# print(\"Training done Sucessfully.....\")\n",
    "\n",
    "# data = load_wikipedia_documents(\"Stored procedure\", load_max_docs=500)\n",
    "# data = load_wikipedia_documents(\"Database trigger\", load_max_docs=500)\n",
    "# data = load_wikipedia_documents(\"Cursor (databases)\", load_max_docs=500)\n",
    "# data = load_wikipedia_documents(\"View (SQL)\", load_max_docs=500)\n",
    "# data = load_wikipedia_documents(\"Information schema\", load_max_docs=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write down the question or Quit/Exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1:  What are the main objectives of this document?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main objectives of the document are to cover theory questions related to SQL, including concepts like Data Control Language (DCL) commands, Transaction Control (TCL) commands, and the process of executing SQL scripts. It also aims to provide practice exercises on these concepts to enhance understanding and knowledge in SQL programming.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2:  do you see anything special about this document\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there seems to be a practice exercise related to SQL queries, particularly focusing on finding Savings Account numbers that have corresponding AddonCredit card transactions.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3:  does this document helps in practicing sql queries for a beginner to get a job as data analyst and mention why?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, this document can be helpful for practicing SQL queries as a beginner aiming to get a job as a data analyst. It provides practice exercises that cover a variety of SQL concepts such as creating databases, writing queries with subqueries, and retrieving specific information from databases. By working through these exercises, beginners can improve their SQL skills, gain hands-on experience in querying databases, and become more proficient in handling data. This practical experience is valuable for aspiring data analysts as it can demonstrate their ability to work with databases and extract meaningful insights from data, which are essential skills for the role.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4:  what are the hard concepts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot provide specific details on the hard concepts in the practice exercise as the content is proprietary to Great Learning. If you have any specific questions or need help understanding any SQL concepts, feel free to ask!\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5:  what are the imp concepts of this documents for a fresher to understanding the sql query for the first time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a fresher looking to understand SQL queries for the first time, here are some important concepts from the provided document:\n",
      "\n",
      "1. **SQL Commands**: Understanding the different types of SQL commands like Data Definition Language (DDL) commands, which are used to define database structures, and Data Manipulation Language (DML) commands, which are used to manipulate data.\n",
      "\n",
      "2. **Data Types in SQL**: Familiarizing yourself with the various data types available in SQL, such as character strings, numeric values, and date/time values.\n",
      "\n",
      "3. **Executing SQL Scripts**: Knowing the two main ways to execute an SQL script - pasting it into the command line or running it from a file, and understanding the process for each.\n",
      "\n",
      "4. **Functions**: Being aware of functions like `now()`, `curdate()`, `curtime()`, `current_timestamp()` that are used to display the current date and time in SQL.\n",
      "\n",
      "5. **Indexing**: Understanding the purpose of using \"INDEX\" in SQL, and how it contributes to faster retrieval of data from large databases.\n",
      "\n",
      "6. **Date Functions**: Learning about date functions like `day`, `month`, `year`, etc., and how to use them with examples in SQL queries.\n",
      "\n",
      "By grasping these key concepts, a fresher can start building a solid foundation in understanding SQL queries and working with databases effectively.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6:  can you tell me those concepts which the difficulty level is higher for a fresher to understand and interpret\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a fresher, the concepts related to window functions in SQL might be a bit challenging to understand and interpret initially due to their complexity. Window functions are used to perform calculations across a set of rows related to the current row and can involve advanced concepts like partitions, frames, and ordering within the dataset. It might take some time and practice to grasp these concepts fully.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7:  does this document provide the knowledge about the windows functions and examples to understand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the document provides information about window functions in SQL, including the different types of window functions and their examples. It also explains the purpose of the \"OVER()\" clause in window functions. If you have any specific questions about window functions or examples, feel free to ask for more details.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for visting us....\n"
     ]
    }
   ],
   "source": [
    "user = True\n",
    "q = 1\n",
    "print(\"Write down the question or Quit/Exit\")\n",
    "\n",
    "while user:\n",
    "    question = input(f\"Prompt {q}: \")\n",
    "\n",
    "    if question in ('q', 'quit', 'Q', '', ' ', 'Quit', 'Exit', 'exit'):\n",
    "        user = False\n",
    "        print(\"\\nThank you for visting us....\")\n",
    "        break\n",
    "    \n",
    "    answer = question_answer_bot(vector_store, question, k=10) # answer['query']\n",
    "    print(answer['result'])\n",
    "    q += 1\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database: Chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings and vector store in chromadb\n",
    "def create_embeddings_chroma(chunks, persist_directory='./chromadb'):\n",
    "    \"\"\"Function which creates the embeddings (OpenAIEmbeddings class), Saves them in a chroma database and returns the vector store object\"\"\"\n",
    "    print(\"Started Creating Embeddings...\", end=' ')\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
    "    vector_store = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory)\n",
    "    print(\"Done...\")\n",
    "    return vector_store\n",
    "\n",
    "# loading embeddings \n",
    "def load_embeddings_chroma(persist_directory='./chromadb'):\n",
    "    \"\"\"Function will load the existing chroma db and return vector store object\"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
    "    vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    return vector_store\n",
    "\n",
    "# Driver Code\n",
    "# data = load_all_documents(\"../files/MySQL\")\n",
    "# chunks = data_chunks(data)\n",
    "# vector_store = create_embeddings_chroma(chunks, './Sessions/chromadb')\n",
    "# db = load_embeddings_chroma('./Sessions/chromadb')\n",
    "# question = \"\"\"What is the whole document about?\"\"\"\n",
    "# answer = question_answer_bot(vector_store, question)\n",
    "# print(answer['query'])\n",
    "# print(answer['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Memory (Chat History) - for follow up questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['chat_history', 'context', 'question'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='\\nUse the following pieces of context to answer the user\\'s question.\\nIf you don\\'t find the answer in the provided context, just respond \"I don\\'t know.\"\\n----------------------------------\\nContext: ```{context}```\\n\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='\\nQuestion: ```{question}```\\nChat History: ```{chat_history}```\\n'))]\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, streaming=True)\n",
    "vector_store = load_embeddings_chroma('./Sessions/chroma_db')\n",
    "retriever = vector_store.as_retriever(search='similarity', search_kwargs={'k':5})\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True) # memory is specifically designed to store and manage conversation history within the langchain application | memory_key='chat_history' gives a memory a label | when retrieving or interacting with stored conversation we will use the key 'chat_history'\n",
    "\n",
    "system_template = r\"\"\"\n",
    "Use the following pieces of context to answer the user's question.\n",
    "If you don't find the answer in the provided context, just respond \"I don't know.\"\n",
    "----------------------------------\n",
    "Context: ```{context}```\n",
    "\n",
    "\"\"\"\n",
    "user_template = \"\"\"\n",
    "Question: ```{question}```\n",
    "Chat History: ```{chat_history}```\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(user_template)\n",
    "]\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "conversation_retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff',\n",
    "    combine_docs_chain_kwargs={'prompt': qa_prompt},\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Driver Code\n",
    "print(qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, model='gpt-3.5-turbo', temperature=0, vector_store=load_embeddings_chroma('./Sessions/chroma_db'), k=5):\n",
    "    \"\"\"Function takes five arguments \n",
    "    question as str type \n",
    "    vector_store: as Chroma object\n",
    "    model: by default 'gpt-3.5-turbo'\n",
    "    temperature: ranges from 0-2 by accurate-creative\n",
    "    k: returns no of output text \n",
    "\n",
    "    as an output returns response object\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature, streaming=True)\n",
    "    retriever = vector_store.as_retriever(search='similarity', search_kwargs={'k':k})\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retreiver=retriever)\n",
    "    response = chain.invoke({'question': question})\n",
    "    return response\n",
    "\n",
    "def ask_with_memory(question, vector_store=load_embeddings_chroma('./Sessions/chroma_db'), chat_history=[], model='gpt-3.5-turbo', temperature=0, k=5):\n",
    "    \"\"\"Function takes five arguments \n",
    "    question as str type \n",
    "    vector_store: as Chroma object\n",
    "    model: by default 'gpt-3.5-turbo'\n",
    "    temperature: ranges from 0-2 by accurate-creative\n",
    "    k: returns no of output text \n",
    "\n",
    "    as an output returns response object, chat_history\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature, streaming=True)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "    conversation_retrieval_chain = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    response = conversation_retrieval_chain({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, response['answer']))\n",
    "    return response, chat_history \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 49\n",
      "Started Creating Embeddings... Done...\n"
     ]
    }
   ],
   "source": [
    "# Loading documents\n",
    "data = load_all_documents(\"../files/MySQL\")\n",
    "chunks = data_chunks(data)\n",
    "vector_store = create_embeddings_chroma(chunks, './Sessions/chroma_db')\n",
    "db = load_embeddings_chroma('./Sessions/chroma_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: which are the above topics represents high difficulty level for a fresher to understand and interpret\n",
      "Assistant: Based on the provided context, the topics from \"GLCA SQL Week3 Day 2 Practice Exercise\" are likely to represent a higher difficulty level for a fresher to understand and interpret compared to the topics from \"GLCA SQL Week3 Day 1 Practice Exercise.\"\n",
      "Human: What is the whole document about?\n",
      "Assistant: The topic of the document mentioned in the conversation is related to SQL practice exercises from Week 3, specifically Day 2.\n",
      "Human: How many types of subqueries we have?\n",
      "Assistant: There are four types of subqueries mentioned in the provided context:\n",
      "1. Single-row sub-query\n",
      "2. Multi-row sub-query\n",
      "3. Multi-column sub-query\n",
      "4. Correlated sub-query\n",
      "Human: can you quote the number of subqueries we have?\n",
      "Assistant: Based on the provided context, there are four types of subqueries mentioned:\n",
      "1. Single-row sub-query\n",
      "2. Multi-row sub-query\n",
      "3. Multi-column sub-query\n",
      "4. Correlated sub-query\n",
      "Human: How many types of window functions we have in sql?\n",
      "Assistant: Based on the provided context, there are 11 different types of window functions in SQL.\n",
      "Follow Up Input: which are the above topics represents high difficulty level for a fresher to understand and interpret\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Use the following pieces of context to answer the user's question.\n",
      "----------------------------------\n",
      "Context: ```Section – A: Theory Questions  \n",
      "1. What is aggregation and how can it  help for large databases ? \n",
      "Aggregation is the process of grouping data from multiple rows into a summarized form to \n",
      "better understand the dataset  \n",
      "Key Aggregation Functions:\n",
      "\n",
      "Section – A: Theory Questions   \n",
      "1. What are the two main ways to execute an SQL script, either by pasting it \n",
      "into the command line or running it from a file and how do they differ in \n",
      "terms of the process used to run the script?\n",
      "\n",
      "By aggregating data, you can obtain a clearer picture of the underlying patterns and trends \n",
      "in large datasets.  \n",
      "These functions allo w you to summarize and analyze data in a meaningful way, making it\n",
      "\n",
      "Section – A: Theory Questions  \n",
      "1. What are the different types of window functions in SQL?  \n",
      "Window functions in SQL are used to perform calculations across a set of rows related to\n",
      "\n",
      "Section – A: Theory Questions  \n",
      "1. list functions used to display the current date and time in SQL . \n",
      "now(), curdate(), curtime(), current_timestamp() are some of the functions used to display \n",
      "the current date and time in sql```\n",
      "\n",
      "\n",
      "Human: \n",
      "Question: ```Which topics from the provided context are likely to represent a higher difficulty level for a fresher to understand and interpret?```\n",
      "Chat History: ```\n",
      "Human: which are the above topics represents high difficulty level for a fresher to understand and interpret\n",
      "Assistant: Based on the provided context, the topics from \"GLCA SQL Week3 Day 2 Practice Exercise\" are likely to represent a higher difficulty level for a fresher to understand and interpret compared to the topics from \"GLCA SQL Week3 Day 1 Practice Exercise.\"\n",
      "Human: What is the whole document about?\n",
      "Assistant: The topic of the document mentioned in the conversation is related to SQL practice exercises from Week 3, specifically Day 2.\n",
      "Human: How many types of subqueries we have?\n",
      "Assistant: There are four types of subqueries mentioned in the provided context:\n",
      "1. Single-row sub-query\n",
      "2. Multi-row sub-query\n",
      "3. Multi-column sub-query\n",
      "4. Correlated sub-query\n",
      "Human: can you quote the number of subqueries we have?\n",
      "Assistant: Based on the provided context, there are four types of subqueries mentioned:\n",
      "1. Single-row sub-query\n",
      "2. Multi-row sub-query\n",
      "3. Multi-column sub-query\n",
      "4. Correlated sub-query\n",
      "Human: How many types of window functions we have in sql?\n",
      "Assistant: Based on the provided context, there are 11 different types of window functions in SQL.```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'which are the above topics represents high difficulty level for a fresher to understand and interpret', 'chat_history': [HumanMessage(content='which are the above topics represents high difficulty level for a fresher to understand and interpret'), AIMessage(content='Based on the provided context, the topics from \"GLCA SQL Week3 Day 2 Practice Exercise\" are likely to represent a higher difficulty level for a fresher to understand and interpret compared to the topics from \"GLCA SQL Week3 Day 1 Practice Exercise.\"'), HumanMessage(content='What is the whole document about?'), AIMessage(content='The topic of the document mentioned in the conversation is related to SQL practice exercises from Week 3, specifically Day 2.'), HumanMessage(content='How many types of subqueries we have?'), AIMessage(content='There are four types of subqueries mentioned in the provided context:\\n1. Single-row sub-query\\n2. Multi-row sub-query\\n3. Multi-column sub-query\\n4. Correlated sub-query'), HumanMessage(content='can you quote the number of subqueries we have?'), AIMessage(content='Based on the provided context, there are four types of subqueries mentioned:\\n1. Single-row sub-query\\n2. Multi-row sub-query\\n3. Multi-column sub-query\\n4. Correlated sub-query'), HumanMessage(content='How many types of window functions we have in sql?'), AIMessage(content='Based on the provided context, there are 11 different types of window functions in SQL.'), HumanMessage(content='which are the above topics represents high difficulty level for a fresher to understand and interpret'), AIMessage(content='Based on the provided context, the topics likely to represent a higher difficulty level for a fresher to understand and interpret are:\\n1. Aggregation and its benefits for large databases\\n2. Different types of window functions in SQL\\n3. Functions used to display the current date and time in SQL\\n\\nThese topics may require a deeper understanding of SQL concepts and functions, making them potentially more challenging for beginners to grasp initially.')], 'answer': 'Based on the provided context, the topics likely to represent a higher difficulty level for a fresher to understand and interpret are:\\n1. Aggregation and its benefits for large databases\\n2. Different types of window functions in SQL\\n3. Functions used to display the current date and time in SQL\\n\\nThese topics may require a deeper understanding of SQL concepts and functions, making them potentially more challenging for beginners to grasp initially.'}\n",
      "which are the above topics represents high difficulty level for a fresher to understand and interpret\n",
      "Based on the provided context, the topics likely to represent a higher difficulty level for a fresher to understand and interpret are:\n",
      "1. Aggregation and its benefits for large databases\n",
      "2. Different types of window functions in SQL\n",
      "3. Functions used to display the current date and time in SQL\n",
      "\n",
      "These topics may require a deeper understanding of SQL concepts and functions, making them potentially more challenging for beginners to grasp initially.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"What is the whole document about?\"\"\"\n",
    "question = \"\"\"How many types of subqueries we have?\"\"\"\n",
    "question = \"\"\"can you quote the number of subqueries we have?\"\"\"\n",
    "question = \"\"\"How many types of window functions we have in sql?\"\"\"\n",
    "question = \"\"\"which are the above topics represents high difficulty level for a fresher to understand and interpret\"\"\"\n",
    "response = ask_question(question, conversation_retrieval_chain)\n",
    "print(response)\n",
    "print(response['question'])\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='which are the above topics represents high difficulty level for a fresher to understand and interpret'\n",
      "content='Based on the provided context, the topics from \"GLCA SQL Week3 Day 2 Practice Exercise\" are likely to represent a higher difficulty level for a fresher to understand and interpret compared to the topics from \"GLCA SQL Week3 Day 1 Practice Exercise.\"'\n",
      "content='What is the whole document about?'\n",
      "content='The topic of the document mentioned in the conversation is related to SQL practice exercises from Week 3, specifically Day 2.'\n",
      "content='How many types of subqueries we have?'\n",
      "content='There are four types of subqueries mentioned in the provided context:\\n1. Single-row sub-query\\n2. Multi-row sub-query\\n3. Multi-column sub-query\\n4. Correlated sub-query'\n",
      "content='can you quote the number of subqueries we have?'\n",
      "content='Based on the provided context, there are four types of subqueries mentioned:\\n1. Single-row sub-query\\n2. Multi-row sub-query\\n3. Multi-column sub-query\\n4. Correlated sub-query'\n",
      "content='How many types of window functions we have in sql?'\n",
      "content='Based on the provided context, there are 11 different types of window functions in SQL.'\n",
      "content='which are the above topics represents high difficulty level for a fresher to understand and interpret'\n",
      "content='Based on the provided context, the topics likely to represent a higher difficulty level for a fresher to understand and interpret are:\\n1. Aggregation and its benefits for large databases\\n2. Different types of window functions in SQL\\n3. Functions used to display the current date and time in SQL\\n\\nThese topics may require a deeper understanding of SQL concepts and functions, making them potentially more challenging for beginners to grasp initially.'\n"
     ]
    }
   ],
   "source": [
    "# chat history key\n",
    "for history in response['chat_history']:\n",
    "    print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Use the following pieces of context to answer the user's question.\n",
      "If you don't find the answer in the provided context, just respond \"I don't know.\"\n",
      "----------------------------------\n",
      "Context: ```specific SQL implementation being used, but the most commonly used data \n",
      "types include: CHAR, VA RCHAR, INT, FLOAT, DOUBLE, DATE, TIME, \n",
      "DATETIME, and TIMESTAMP  \n",
      " \n",
      "2. What is the difference between Char and Varchar data types in SQL?\n",
      "\n",
      "Section – A: Theory Questions  \n",
      " \n",
      "1. How many data types are available in SQL?  \n",
      "There are several data types in SQL, including character strings, numeric values, \n",
      "and date/time values. The exact number of data types can vary depending on the\n",
      "\n",
      "3. Explain the concept of SQL commands and how many types . \n",
      "A SQL command is a set of instructions written in the SQL language that is used \n",
      "to interact with a database. These commands are used to insert, update, and\n",
      "\n",
      "2. How ma ny formatting and conversion functions are available in SQL, and \n",
      "what are they used for?  (not applicable using code eval)  \n",
      "Cast :  \n",
      " Convert data into different data types such as char, time, date, datetime\n",
      "\n",
      "retrieve data from databases, as well as to create, modify, and delete database \n",
      "structures like tabl es and indexes.  \n",
      " \n",
      "There are several types of SQL commands:  \n",
      " \n",
      "● Data Definition Language (DDL) commands:  These commands are```\n",
      "\n",
      "\n",
      "Human: \n",
      "Question: ```What type of triggers we do have in sql?```\n",
      "Chat History: ``````\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = load_embeddings_chroma('./Sessions/chroma_db')\n",
    "question = \"\"\"How many types of commands we have in sql?\"\"\"\n",
    "question = \"\"\"What type of triggers we do have in sql?\"\"\"\n",
    "response = ask_question(question, conversation_retrieval_chain)\n",
    "response['question']\n",
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
