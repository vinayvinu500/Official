{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project Title: Custom ChatGPT App with Langchain\n",
    "\n",
    "***Description***: The Official ChatGPT is great but need to be tailored as per the specific needs\n",
    "\n",
    "\n",
    "# Advantages\n",
    "\n",
    "- ***Increased Security***: Imply the security measures which are specific to organisation needs. i.e, control the access to the app via users perspective in which we can ensure of the confidental data and intectual property \n",
    "\n",
    "- ***Improved User Experience***: Customize the Layout, Branding, functionality to match the organizational needs. Add features like integration of customer relation management system or knowledge base \n",
    "\n",
    "- ***Great Flexibility***: New features and functionality as needed and not limited to prebuilt chatgpt app like we can make use of llama2 from huggingfacehub and integrate and modify app functionality accordingly to meet the customer specification let say to have a feature to track the progress of the customer or project  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r ../LLM/requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Sucessfull!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "try: \n",
    "    file = '../LLM/.env'\n",
    "    keys = find_dotenv(file,raise_error_if_not_found=True)\n",
    "    load_dotenv(keys, override=True)\n",
    "    # print(os.environ.get('OPENAI_API_KEY'))\n",
    "    print(\"Initialize Sucessfull!\")\n",
    "except:\n",
    "    print(\"Need to Initialize Again...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory\n",
    "\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, DuckDuckGoSearchAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent, create_openai_tools_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatBot\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1, streaming=True)\n",
    "\n",
    "# History of Sessions\n",
    "history = FileChatMessageHistory('./Sessions/CustomGPT_chat_history.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history', # chat memory will be stored in the chat history key, the key is used later in the chatprompttemplate\n",
    "    chat_memory=history,\n",
    "    return_messages=True # *necessary step which tells the memory to return the chat history as a list of messages instead of string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a Chatbot having a conservation with a Human. Answer the following as best as you can.\n",
    "Questions: {q}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "hubprompt = hub.pull('hwchase17/openai-tools-agent') # react base agent\n",
    "# print(hubprompt.input_variables)\n",
    "# print(hubprompt.template)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variable=['content'],\n",
    "    messages=[\n",
    "        SystemMessage(content='You are a Chatbot having a conservation with a Human.'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'), # memory will be stored\n",
    "        HumanMessagePromptTemplate.from_template('{content}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "# response = chain.invoke({'content':question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Python Repl\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(name='Python_REPL', func=python_repl.run, description='Useful when you need to use python interpreter to answer a question. You should input Python code.')\n",
    "\n",
    "\n",
    "# 2. Wikipedia \n",
    "wikipedia_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_conten_chars_max=1500)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)\n",
    "# wikipedia.invoke({'query': 'llamaindex'})\n",
    "wikipedia_tool = Tool(name='Wikipedia', func=wikipedia.run, description='Useful when you need to look up a topic, etc on Wikipedia.')\n",
    "\n",
    "# 3. DuckDuckGo\n",
    "search_api_wrapper = DuckDuckGoSearchAPIWrapper(region='in-en', max_results=3, safesearch='moderate') # regions : https://serpapi.com/duckduckgo-regions\n",
    "search = DuckDuckGoSearchResults(api_wrapper=search_api_wrapper)  # source='news'\n",
    "# search.run('langchain')\n",
    "duckduckgo_tool = Tool(name='DuckDuckGoSearch', func=search.run, description='Useful when you need to look up a recent update to date information on internet.')\n",
    "\n",
    "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
    "\n",
    "# agent\n",
    "agent = create_openai_tools_agent(llm, tools, hubprompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=False, handle_parsing_errors=True, max_iterations=10)\n",
    "\n",
    "# Testing\n",
    "# question = \"Generate Steps to learn LLamaIndex and show me one use-case using python\"\n",
    "# response = agent_executor.invoke({'input': prompt_template.format(q=question)})\n",
    "# response = agent_executor.invoke({\"input\": prompt_template.format(q=question)}) # , return_only_outputs=True\n",
    "# print(response['input'])\n",
    "# print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:  what are the questions I have asked previously till so far? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the summaries of the topics you asked about:\n",
      "\n",
      "1. Winston Churchill: Sir Winston Leonard Spencer Churchill was a British statesman, soldier, and writer who served as Prime Minister of the United Kingdom during World War II. He was known for his leadership and is considered one of the greatest prime ministers in British history.\n",
      "\n",
      "2. \"We Shall Fight on the Beaches\": This speech was delivered by Winston Churchill to the House of Commons on 4 June 1940 during World War II. It was a declaration of resolve to continue the fight against Nazi Germany.\n",
      "\n",
      "3. Battle of France: The Battle of France was the German invasion of France during World War II, leading to the fall of France and the occupation of certain regions by the Germans.\n",
      "\n",
      "4. French Army during World War II: The French Army played a significant role during World War II, particularly in the Battle of France. The invasion by German forces led to the defeat and occupation of France.\n",
      "\n",
      "5. Relationship between Winston Churchill and the military: Winston Churchill had a close relationship with the British Armed Forces during his time as Prime Minister. He worked closely with military leaders, supported the troops, and made critical decisions during wartime.\n",
      "\n",
      "Please let me know if you need more information or have any other questions.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:  from the above questions which are meant to be most imp one?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important question among the ones you have asked so far could be the one about Winston Churchill's famous speech \"We Shall Fight on the Beaches.\" This question delves into a significant moment in history during World War II and highlights Churchill's leadership and determination during a critical period. This speech is widely recognized and symbolizes the resilience and resolve of the British people in the face of adversity.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:  why it is so special and can you mention some bullet points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"We Shall Fight on the Beaches\" speech by Winston Churchill is considered special for several reasons. Here are some key points that make this speech significant:\n",
      "\n",
      "1. Symbol of Determination: The speech symbolizes the unwavering determination of the British people to continue the fight against Nazi Germany despite facing great adversity.\n",
      "\n",
      "2. Inspirational Tone: Churchill's powerful and inspirational words in the speech uplifted the morale of the British population and instilled a sense of resilience during a challenging time in World War II.\n",
      "\n",
      "3. Defiance Against Aggression: The speech reflects Churchill's defiance against the aggression of the enemy and his commitment to resist and push back against the German forces.\n",
      "\n",
      "4. Historic Context: The speech was delivered at a crucial moment when Britain stood alone against the German military advancement, making it a pivotal moment in British history.\n",
      "\n",
      "5. Leadership Display: Churchill's leadership and strength in articulating a clear message of resolve and unity to the nation showcased his ability to rally the country during wartime.\n",
      "\n",
      "6. Endurance and Perseverance: The speech emphasized the values of endurance and perseverance in the face of overwhelming odds, inspiring a sense of unity and purpose among the British people.\n",
      "\n",
      "Overall, the \"We Shall Fight on the Beaches\" speech holds significance as a powerful declaration of resolve and defiance that rallied the British population during a critical phase of World War II.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:  thank you!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome! If you have any more questions in the future or need further assistance, feel free to ask. Have a great day!\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process End ...\n"
     ]
    }
   ],
   "source": [
    "user = True\n",
    "\n",
    "while user:\n",
    "    question = input(\"Prompt: \") \n",
    "    \n",
    "    if question in (' ', '', 'exit', 'quit', 'q', 'Q'):\n",
    "        print(\"\\nProcess End ...\")\n",
    "        break\n",
    "\n",
    "    response = agent_executor.invoke({\"input\": question})\n",
    "    for chunk in response['output']:\n",
    "        print(chunk, end='', flush=True)\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
